{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c32ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "#os.environ[\"OPENAI_API_KEY_SWEDEN\"] = \"\"\n",
    "#os.environ[\"OPENAI_API_BASE_SWEDEN\"] = \"\"\n",
    "\n",
    "api_version = \"2024-03-01-preview\"\n",
    "api_key = os.environ[\"OPENAI_API_KEY_SWEDEN\"]\n",
    "api_base = os.environ[\"OPENAI_API_BASE_SWEDEN\"]\n",
    "\n",
    "model = \"gpt-4\"\n",
    "model_dalle = \"dall-e-3\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_version=api_version,\n",
    "        api_key=api_key,\n",
    "        azure_endpoint=api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670d6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt):\n",
    "    print(\"Image to be generated\\n\")   \n",
    "    \n",
    "    result = client.images.generate(\n",
    "        model=model_dalle, # the name of your DALL-E 3 deployment\n",
    "        prompt=prompt,\n",
    "        n=1\n",
    "    )\n",
    "    \n",
    "    image_url = json.loads(result.model_dump_json())[\"data\"][0][\"url\"]\n",
    "    \n",
    "    #Image(url=image_url)\n",
    "    #print(image_url)\n",
    "    \n",
    "    return json.dumps({\"image_url\": image_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2261edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(input_user):\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": input_user}]\n",
    "    \n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"generate_image\",\n",
    "                \"description\": \"Generate an image given with the given prompt\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"prompt\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Description of the image to be generated\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"prompt\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    \n",
    "    if tool_calls:\n",
    "\n",
    "        available_functions = {\n",
    "            \"generate_image\": generate_image\n",
    "        }\n",
    "        messages.append(response_message)\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                prompt=function_args.get(\"prompt\")\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print(function_name)\n",
    "        \n",
    "        second_response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        \n",
    "        return second_response.choices[0].message.content\n",
    "    \n",
    "    else:\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response_message.content})\n",
    "        \n",
    "        return response_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ef77de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image to be generated\n",
      "\n",
      "generate_image\n",
      "Here is a picture of a cat for you:\n",
      "![A Cat Picture](https://dalleprodsec.blob.core.windows.net/private/images/bd5535e4-cd8c-4178-b78c-d2663b17a511/generated_00.png?se=2024-05-11T11%3A17%3A51Z&sig=tR7pzPofN%2FDIRWZtFrF0FLMI6NKlM6Fwtdtn2SkstMU%3D&ske=2024-05-17T09%3A28%3A03Z&skoid=e52d5ed7-0657-4f62-bc12-7e5dbb260a96&sks=b&skt=2024-05-10T09%3A28%3A03Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\n"
     ]
    }
   ],
   "source": [
    "print(run_conversation(\"Show me the picture of a cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ffa6816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, as an AI, I don't have real-time data access, but as of 2020, estimates suggest there are roughly 600 million domestic cats worldwide. However, please note that the actual number may vary as it's challenging to accurately count the global feline population, particularly including stray and feral cats. You may want to check the latest statistics from a reliable source.\n"
     ]
    }
   ],
   "source": [
    "print(run_conversation(\"How many cats exist in the world?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19c056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_user = \"Show me the picture of a cat running in a gold desert\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": input_user}]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"generate_image\",\n",
    "                \"description\": \"Generate an image given with the given prompt\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"prompt\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Description of the image to be generated\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"prompt\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7f41815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9NIcXMLUIEIgUw8kvRPllqSC5ZcwA', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jRMAR87tP0VxRZ6NuddI0LQK', function=Function(arguments='{\\n  \"prompt\": \"a cat running in a gold desert\"\\n}', name='generate_image'), type='function')]), content_filter_results={})], created=1715340149, model='gpt-4', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=21, prompt_tokens=69, total_tokens=90), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a516baa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: chatcmpl-9NIcXMLUIEIgUw8kvRPllqSC5ZcwA\n",
      "Created: 1715340149\n",
      "Model: gpt-4\n",
      "Usage - Completion Tokens: 21\n",
      "Usage - Prompt Tokens: 69\n",
      "Usage - Total Tokens: 90\n",
      "\n",
      "Choices:\n",
      "Finish Reason: tool_calls\n",
      "Index: 0\n",
      "Message Role: assistant\n",
      "Tool Calls:\n",
      "Tool Call ID: call_jRMAR87tP0VxRZ6NuddI0LQK\n",
      "Tool Call Function: Function(arguments='{\\n  \"prompt\": \"a cat running in a gold desert\"\\n}', name='generate_image')\n",
      "Tool Call Type: function\n"
     ]
    }
   ],
   "source": [
    "response_id = response.id\n",
    "choices = response.choices\n",
    "created = response.created\n",
    "model = response.model\n",
    "usage = response.usage\n",
    "\n",
    "print(\"Response ID:\", response_id)\n",
    "print(\"Created:\", created)\n",
    "print(\"Model:\", model)\n",
    "print(\"Usage - Completion Tokens:\", usage.completion_tokens)\n",
    "print(\"Usage - Prompt Tokens:\", usage.prompt_tokens)\n",
    "print(\"Usage - Total Tokens:\", usage.total_tokens)\n",
    "\n",
    "print(\"\\nChoices:\")\n",
    "for choice in choices:\n",
    "    print(\"Finish Reason:\", choice.finish_reason)\n",
    "    print(\"Index:\", choice.index)\n",
    "    message = choice.message\n",
    "    if message:\n",
    "        print(\"Message Role:\", message.role)\n",
    "        tool_calls = message.tool_calls\n",
    "        if tool_calls:\n",
    "            print(\"Tool Calls:\")\n",
    "            for tool_call in tool_calls:\n",
    "                print(\"Tool Call ID:\", tool_call.id)\n",
    "                print(\"Tool Call Function:\", tool_call.function)\n",
    "                print(\"Tool Call Type:\", tool_call.type)\n",
    "    content_filter_results = choice.content_filter_results\n",
    "    if content_filter_results:\n",
    "        print(\"Content Filter Results:\", content_filter_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c54d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
